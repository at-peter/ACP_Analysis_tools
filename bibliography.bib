@article{DBLP:Benchmarking,
  author    = {Georgios Papoudakis and
               Filippos Christianos and
               Lukas Sch{\"{a}}fer and
               Stefano V. Albrecht},
  title     = {Benchmarking Multi-Agent Deep Reinforcement Learning Algorithms in Cooperative Tasks},
  journal   = {CoRR},
  volume    = {abs/2006.07869},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.07869},
  eprinttype = {arXiv},
  eprint    = {2006.07869},
  timestamp = {Sun, 29 Aug 2021 18:23:06 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-07869.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:Qmix,
  author    = {Tabish Rashid and
               Mikayel Samvelyan and
               Christian Schr{\"{o}}der de Witt and
               Gregory Farquhar and
               Jakob N. Foerster and
               Shimon Whiteson},
  title     = {{QMIX:} Monotonic Value Function Factorisation for Deep Multi-Agent
               Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1803.11485},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.11485},
  eprinttype = {arXiv},
  eprint    = {1803.11485},
  timestamp = {Mon, 13 Aug 2018 16:46:51 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-11485.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{sunehag2017vdn,
  title={Value-decomposition networks for cooperative multi-agent learning},
  author={Sunehag, Peter and Lever, Guy and Gruslys, Audrunas and Czarnecki, Wojciech Marian and Zambaldi, Vinicius and Jaderberg, Max and Lanctot, Marc and Sonnerat, Nicolas and Leibo, Joel Z and Tuyls, Karl and others},
  journal={arXiv preprint arXiv:1706.05296},
  year={2017}
}


@inproceedings{atrazhev2022investigating,
  title={Investigating Effects of Centralized Learning Decentralized Execution on Team Coordination in the Level Based Foraging Environment as a Sequential Social Dilemma},
  author={Atrazhev, Peter and Musilek, Petr},
  booktitle={International Conference on Practical Applications of Agents and Multi-Agent Systems},
  pages={15--23},
  year={2022},
  organization={Springer}
}


@article{DBLP:maddpg,
  author    = {Ryan Lowe and
               Yi Wu and
               Aviv Tamar and
               Jean Harb and
               Pieter Abbeel and
               Igor Mordatch},
  title     = {Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  journal   = {CoRR},
  volume    = {abs/1706.02275},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.02275},
  eprinttype = {arXiv},
  eprint    = {1706.02275},
  timestamp = {Mon, 13 Aug 2018 16:47:09 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/LoweWTHAM17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


  @Inbook{Oliehoek2016,
author="Oliehoek, Frans A.
and Amato, Christopher",
title="The Decentralized POMDP Framework",
bookTitle="A Concise Introduction to Decentralized POMDPs",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="11--32",
abstract="In this chapter we formally define the Dec-POMDP model. It is a member of the family of discrete-time planning frameworks that are derived from the single-agent Markov decision process.",
}

@article{mnih2015dqn,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{DBLP:contrastingCentralizedDecentralized,
  author    = {Xueguang Lyu and
               Yuchen Xiao and
               Brett Daley and
               Christopher Amato},
  title     = {Contrasting Centralized and Decentralized Critics in Multi-Agent Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/2102.04402},
  year      = {2021},
  url       = {https://arxiv.org/abs/2102.04402},
  eprinttype = {arXiv},
  eprint    = {2102.04402},
  timestamp = {Wed, 10 Feb 2021 15:24:31 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2102-04402.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:MAPPO,
  author    = {Chao Yu and
               Akash Velu and
               Eugene Vinitsky and
               Yu Wang and
               Alexandre M. Bayen and
               Yi Wu},
  title     = {The Surprising Effectiveness of {MAPPO} in Cooperative, Multi-Agent
               Games},
  journal   = {CoRR},
  volume    = {abs/2103.01955},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.01955},
  eprinttype = {arXiv},
  eprint    = {2103.01955},
  timestamp = {Wed, 18 Jan 2023 07:53:41 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-01955.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{DBLP:A3C,
  title = 	 {Asynchronous Methods for Deep Reinforcement Learning},
  author = 	 {Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1928--1937},
  year = 	 {2016},
  editor = 	 {Balcan, Maria Florina and Weinberger, Kilian Q.},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/mniha16.pdf},
  url = 	 {https://proceedings.mlr.press/v48/mniha16.html},
  abstract = 	 {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.}
}

@inproceedings{LBF,
  title={Shared Experience Actor-Critic for Multi-Agent Reinforcement Learning},
  author={Christianos, Filippos and Schäfer, Lukas and Albrecht, Stefano V},
  booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
  year={2020}
}

@article{tumerdifferencerewards,
  title={A survey of collectives},
  author={Tumer, Kagan and Wolpert, David},
  journal={Collectives and the design of complex systems},
  pages={1--42},
  year={2004},
  publisher={Springer}
}

@inproceedings{colby2016local,
  title={Local approximation of difference evaluation functions},
  author={Colby, Mitchell and Duchow-Pressley, Theodore and Chung, Jen Jen and Tumer, Kagan},
  booktitle={Proceedings of the 2016 International Conference on Autonomous Agents \& Multiagent Systems},
  pages={521--529},
  year={2016}
}

@article{agogino2008analyzing,
  title={Analyzing and visualizing multiagent rewards in dynamic and stochastic domains},
  author={Agogino, Adrian K and Tumer, Kagan},
  journal={Autonomous Agents and Multi-Agent Systems},
  volume={17},
  pages={320--338},
  year={2008},
  publisher={Springer}
}

@inproceedings{proper2012modeling,
  title={Modeling difference rewards for multiagent learning.},
  author={Proper, Scott and Tumer, Kagan},
  booktitle={AAMAS},
  pages={1397--1398},
  year={2012}
}

@article{alex-paper,
    title = {Reinforcement learning-driven local transactive energy market for distributed energy resources},
    journal = {Energy and AI},
    volume = {8},
    pages = {100150},
    year = {2022},
    issn = {2666-5468},
    url = {https://www.sciencedirect.com/science/article/pii/S2666546822000118%7D,
    author = {Steven Zhang and Daniel May and Mustafa Gül and Petr Musilek}
    }
}

@article{DBLP:ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06347},
  eprinttype = {arXiv},
  eprint    = {1707.06347},
  timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
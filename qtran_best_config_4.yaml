action_selector: epsilon_greedy
agent: rnn
agent_output_type: q
batch_size: 32
batch_size_run: 1
buffer_cpu_only: true
buffer_size: 5000
checkpoint_path: ''
double_q: true
env: gymma
env_args:
  key: Foraging-8x8-2p-2f-coop-v0
  pretrained_wrapper: null
  time_limit: 25
epsilon_anneal_time: 50000
epsilon_finish: 0.05
epsilon_start: 1.0
evaluate: false
evaluation_epsilon: 0.0
gamma: 0.99
grad_norm_clip: 10
hidden_dim: 64
hypergroup: hp_grp_173
label: default_label
learner: qtran_learner
learner_log_interval: 10000
load_step: 0
local_results_path: results
log_interval: 25000
lr: 0.0005
mac: basic_mac
mixer: qtran_base
mixing_embed_dim: 64
name: qtran_best_config_4
network_size: small
nopt_min_loss: 0.1
obs_agent_id: true
obs_last_action: true
opt_loss: 1
optim_alpha: 0.99
optim_eps: 1.0e-05
qtran_arch: qtran_paper
repeat_id: 1
runner: episode
runner_log_interval: 10000
save_model: false
save_model_interval: 50000
save_replay: false
seed: 1
standardise_rewards: true
t_max: 2050000
target_update_interval: 200
target_update_interval_or_tau: 200
test_greedy: true
test_interval: 25000
test_nepisode: 100
use_cuda: false
use_rnn: false
use_tensorboard: false
